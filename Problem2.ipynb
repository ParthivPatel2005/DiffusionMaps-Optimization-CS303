{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: cma in c:\\users\\parth\\appdata\\roaming\\python\\python310\\site-packages (4.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\parth\\appdata\\roaming\\python\\python310\\site-packages (from cma) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install cma\n",
    "# %pip install cma // to install in same environment as jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize, dual_annealing\n",
    "import cma\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Define Benchmark Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rosenbrock Function\n",
    "def rosenbrock(x):\n",
    "    return sum(100.0*(x[1:] - x[:-1]**2.0)**2.0 + (1 - x[:-1])**2.0)\n",
    "\n",
    "# Rastrigin Function\n",
    "def rastrigin(x):\n",
    "    return 10*len(x) + sum(x**2 - 10*np.cos(2*np.pi*x))\n",
    "\n",
    "# Ackley Function\n",
    "def ackley(x):\n",
    "    first_sum = np.sum(x**2)\n",
    "    second_sum = np.sum(np.cos(2*np.pi*x))\n",
    "    n = len(x)\n",
    "    return -20*np.exp(-0.2*np.sqrt(first_sum/n)) - np.exp(second_sum/n) + 20 + np.e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization on Benchmark Functions (Task 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark Results:\n",
      "\n",
      "Rosenbrock function:\n",
      "Nelder-Mead: 1.0423182566004013e-09\n",
      "Simulated Annealing: 8.888116134953508e-12\n",
      "CMA-ES: 1.1518594611976732e-17\n",
      "\n",
      "Rastrigin function:\n",
      "Nelder-Mead: 17.90920266864526\n",
      "Simulated Annealing: 2.842170943040401e-14\n",
      "CMA-ES: 0.2419253812634281\n",
      "\n",
      "Ackley function:\n",
      "Nelder-Mead: 9.00109350489619\n",
      "Simulated Annealing: 1.7545432218213364e-08\n",
      "CMA-ES: 9.001093478292006\n"
     ]
    }
   ],
   "source": [
    "methods = ['Nelder-Mead', 'Simulated Annealing', 'CMA-ES']\n",
    "functions = {'Rosenbrock': rosenbrock, 'Rastrigin': rastrigin, 'Ackley': ackley}\n",
    "bounds = [(-5,5), (-5,5)]\n",
    "initial_guess = [3,3]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for fname, func in functions.items():\n",
    "    results[fname] = {}\n",
    "    \n",
    "    # Nelder-Mead\n",
    "    res_nm = minimize(func, initial_guess, method='Nelder-Mead')\n",
    "    \n",
    "    # Simulated Annealing\n",
    "    res_sa = dual_annealing(func, bounds=bounds)\n",
    "    \n",
    "    # CMA-ES\n",
    "    res_cma = cma.fmin(func, initial_guess, sigma0=0.5, options={'verb_disp': False})\n",
    "    \n",
    "    results[fname]['Nelder-Mead'] = res_nm.fun\n",
    "    results[fname]['Simulated Annealing'] = res_sa.fun\n",
    "    results[fname]['CMA-ES'] = res_cma[1]\n",
    "\n",
    "print(\"Benchmark Results:\")\n",
    "for fname in results:\n",
    "    print(f\"\\n{fname} function:\")\n",
    "    for method in methods:\n",
    "        print(f\"{method}: {results[fname][method]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST Dataset & Preprocess (Task 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fetch_openml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mnist \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_openml\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmnist_784\u001b[39m\u001b[38;5;124m'\u001b[39m, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m X, y \u001b[38;5;241m=\u001b[39m mnist\u001b[38;5;241m.\u001b[39mdata[:\u001b[38;5;241m2000\u001b[39m], mnist\u001b[38;5;241m.\u001b[39mtarget[:\u001b[38;5;241m2000\u001b[39m] \u001b[38;5;66;03m# subset for speed\u001b[39;00m\n\u001b[0;32m      4\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fetch_openml' is not defined"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist.data[:2000], mnist.target[:2000] # subset for speed\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Define Hyperparameter Optimization Function (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_eval(params):\n",
    "    C, gamma = params[0], params[1]\n",
    "    clf = SVC(C=C, gamma=gamma)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=3)\n",
    "    return 1 - scores.mean() # minimize error rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Hyperparameter Tuning with Optimization Methods (Task 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_bounds = [(0.1,100), (1e-4,1)]\n",
    "\n",
    "# Nelder-Mead Optimization\n",
    "res_svm_nm = minimize(svm_eval, x0=[1.0, 0.01], method='Nelder-Mead')\n",
    "\n",
    "# Simulated Annealing Optimization\n",
    "res_svm_sa = dual_annealing(svm_eval, bounds=hp_bounds)\n",
    "\n",
    "# CMA-ES Optimization\n",
    "res_svm_cma = cma.fmin(svm_eval, [1.0, 0.01], sigma0=0.5, options={'bounds': [np.array([0.1,1e-4]), np.array([100,1])]})\n",
    "\n",
    "print(\"\\nSVM Hyperparameter Tuning Results:\")\n",
    "print(\"Nelder-Mead optimal params:\", res_svm_nm.x)\n",
    "print(\"Simulated Annealing optimal params:\", res_svm_sa.x)\n",
    "print(\"CMA-ES optimal params:\", res_svm_cma[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Final Test Accuracy (Task 2 Continued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(params):\n",
    "    C_opt,gamma_opt=params[0],params[1]\n",
    "    clf=SVC(C=C_opt,gamma=gamma_opt).fit(X_train,y_train)\n",
    "    return clf.score(X_test,y_test)\n",
    "\n",
    "acc_nm=test_accuracy(res_svm_nm.x)\n",
    "acc_sa=test_accuracy(res_svm_sa.x)\n",
    "acc_cma=test_accuracy(res_svm_cma[0])\n",
    "\n",
    "print(\"\\nFinal Test Accuracy:\")\n",
    "print(f\"Nelder-Mead Accuracy: {acc_nm:.4f}\")\n",
    "print(f\"Simulated Annealing Accuracy: {acc_sa:.4f}\")\n",
    "print(f\"CMA-ES Accuracy: {acc_cma:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Visualization of Optimization Trajectories (Task 3 Example with Rosenbrock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "x=np.linspace(-3,3,100)\n",
    "y=np.linspace(-3,3,100)\n",
    "X,Y=np.meshgrid(x,y)\n",
    "Z=(1-X)**2+100*(Y-X**2)**2\n",
    "\n",
    "fig=plt.figure(figsize=(10,7))\n",
    "ax=fig.add_subplot(111,projection='3d')\n",
    "ax.plot_surface(X,Y,Z,cmap='viridis',alpha=0.8)\n",
    "\n",
    "ax.set_title('Rosenbrock Function')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('f(X,Y)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Landscape Visualization (Task 3 Example for SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_vals=np.logspace(-1,2,num=10)\n",
    "gamma_vals=np.logspace(-4,-1,num=10)\n",
    "\n",
    "accuracy_grid=np.zeros((len(C_vals),len(gamma_vals)))\n",
    "\n",
    "for i,C in enumerate(C_vals):\n",
    "    for j,gamma in enumerate(gamma_vals):\n",
    "        clf=SVC(C=C,gamma=gamma).fit(X_train,y_train)\n",
    "        accuracy_grid[i,j]=clf.score(X_test,y_test)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(accuracy_grid,cmap='viridis',origin='lower')\n",
    "plt.colorbar(label='Accuracy')\n",
    "plt.xticks(range(len(gamma_vals)),np.round(gamma_vals,4),rotation=45)\n",
    "plt.yticks(range(len(C_vals)),np.round(C_vals,3))\n",
    "plt.xlabel('Gamma')\n",
    "plt.ylabel('C')\n",
    "plt.title('SVM Hyperparameter Landscape')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
